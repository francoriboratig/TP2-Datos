{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Red convolucional.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/francoriboratig/TP2-Datos/blob/master/Red%20neuronal%20con%20text%20embeddings%2C%20features%20e%20hyperparameter%20automatic%20tunning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wcmc7yo2Iaz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7f5d6985-3e1c-4489-e0e3-d054b8820bbb"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import keras.models\n",
        "import keras.layers as layers\n",
        "from keras.models import Sequential\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "!pip install -q tensorflow-hub\n",
        "import tensorflow_hub as hub\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "tf.compat.v1.enable_eager_execution(\n",
        "    config=None, device_policy=None, execution_mode=None\n",
        ")\n",
        "\n",
        "!pip install talos\n",
        "import talos\n",
        "import datetime as dt\n",
        "\n",
        "print(\"Version: \", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print(\"Hub version: \", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: talos in /usr/local/lib/python3.6/dist-packages (0.6.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from talos) (1.18.5)\n",
            "Requirement already satisfied: tensorflow==1.14.0 in /usr/local/lib/python3.6/dist-packages (from talos) (1.14.0)\n",
            "Requirement already satisfied: astetik in /usr/local/lib/python3.6/dist-packages (from talos) (1.9.9)\n",
            "Requirement already satisfied: keras==2.3.0 in /usr/local/lib/python3.6/dist-packages (from talos) (2.3.0)\n",
            "Requirement already satisfied: wrangle in /usr/local/lib/python3.6/dist-packages (from talos) (0.6.7)\n",
            "Requirement already satisfied: chances in /usr/local/lib/python3.6/dist-packages (from talos) (0.1.9)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from talos) (0.0)\n",
            "Requirement already satisfied: statsmodels>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from talos) (0.11.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from talos) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from talos) (4.41.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from talos) (1.0.5)\n",
            "Requirement already satisfied: kerasplotlib in /usr/local/lib/python3.6/dist-packages (from talos) (0.1.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->talos) (1.1.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->talos) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->talos) (1.14.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->talos) (1.14.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->talos) (1.30.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->talos) (0.9.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->talos) (0.8.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->talos) (1.12.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->talos) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->talos) (3.12.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->talos) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->talos) (0.34.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->talos) (0.3.3)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->talos) (1.0.8)\n",
            "Requirement already satisfied: geonamescache in /usr/local/lib/python3.6/dist-packages (from astetik->talos) (1.2.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0->talos) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0->talos) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0->talos) (3.13)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->talos) (0.22.2.post1)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.6/dist-packages (from statsmodels>=0.11.0->talos) (0.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->talos) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->talos) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->talos) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->talos) (2.10)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->talos) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->talos) (2.8.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from kerasplotlib->talos) (5.5.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0->talos) (49.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0->talos) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0->talos) (3.2.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->talos) (0.16.0)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->kerasplotlib->talos) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->kerasplotlib->talos) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->kerasplotlib->talos) (1.0.18)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->kerasplotlib->talos) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->kerasplotlib->talos) (2.1.3)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->kerasplotlib->talos) (4.3.3)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->kerasplotlib->talos) (0.7.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0->talos) (1.7.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->kerasplotlib->talos) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->kerasplotlib->talos) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->kerasplotlib->talos) (0.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0->talos) (3.1.0)\n",
            "Version:  1.14.0\n",
            "Eager mode:  True\n",
            "Hub version:  0.8.0\n",
            "GPU is NOT AVAILABLE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pHyci8dgDGq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "outputId": "7cbb61a6-2a0d-4618-ac59-184866918b36"
      },
      "source": [
        "# CARGAMOS LOS CSV\n",
        "url_train_con_features = 'https://raw.githubusercontent.com/francoriboratig/TP2-Datos/master/train-features.csv'\n",
        "url_test_con_features = 'https://raw.githubusercontent.com/francoriboratig/TP2-Datos/master/test-features.csv'\n",
        "\n",
        "train_df = pd.read_csv(url_train_con_features)\n",
        "test_df = pd.read_csv(url_test_con_features)\n",
        "\n",
        "train_df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>character_count</th>\n",
              "      <th>word_count</th>\n",
              "      <th>contains_word_fire</th>\n",
              "      <th>contains_word_storm</th>\n",
              "      <th>contains_word_flood</th>\n",
              "      <th>contains_word_death</th>\n",
              "      <th>contains_word_love</th>\n",
              "      <th>has_mentions</th>\n",
              "      <th>amount_of_exclamation_marks</th>\n",
              "      <th>amount_of_interrogation_marks</th>\n",
              "      <th>has_link</th>\n",
              "      <th>stopwords_count</th>\n",
              "      <th>contains_countries</th>\n",
              "      <th>contains_cities</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "      <td>69</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>7</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>3</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "      <td>133</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>13</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "      <td>65</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "      <td>88</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>10</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  id keyword  ... stopwords_count contains_countries  contains_cities\n",
              "0           0   1     NaN  ...               7              False            False\n",
              "1           1   4     NaN  ...               3               True            False\n",
              "2           2   5     NaN  ...              13              False            False\n",
              "3           3   6     NaN  ...               2              False            False\n",
              "4           4   7     NaN  ...              10              False            False\n",
              "\n",
              "[5 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgP7Jo-zhsnW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "502c26fd-4559-4b31-dd16-7ccfa3ac8ac5"
      },
      "source": [
        "# LIMPIAMOS Y CHUSMEAMOS\n",
        "train_df = train_df.drop(['Unnamed: 0', 'keyword', 'location'], axis = 1)\n",
        "train_df.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 17)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4L8qpXPa1Bmr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_df = train_df.pop('target')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cw0HFe5EkJae",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "55345d51-9bc6-40bb-b5de-350e585b7531"
      },
      "source": [
        "# HACEMOS UN EMBEDDING PROVISTO POR TensorFlow Hub, por fuera del modelo, de esa forma puedo agregarle features al array\n",
        "\n",
        "embedding_url = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\n",
        "\n",
        "hub_layer = hub.KerasLayer(embedding_url,\n",
        "                           input_shape = [], \n",
        "                           dtype = tf.string,\n",
        "                           trainable = True)\n",
        "\n",
        "train_text_array = np.asarray(train_df['text'])\n",
        "train_text_embedded = hub_layer(train_text_array)\n",
        "train_text_embedded_array = train_text_embedded.numpy()\n",
        "train_text_embedded_df = pd.DataFrame(data = train_text_embedded_array)\n",
        "\n",
        "train_text_embedded_df"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.007239</td>\n",
              "      <td>0.156896</td>\n",
              "      <td>1.295307</td>\n",
              "      <td>-0.040780</td>\n",
              "      <td>-0.160369</td>\n",
              "      <td>-1.200443</td>\n",
              "      <td>-0.404513</td>\n",
              "      <td>-0.523973</td>\n",
              "      <td>-0.235587</td>\n",
              "      <td>-0.350222</td>\n",
              "      <td>-0.289882</td>\n",
              "      <td>-0.471979</td>\n",
              "      <td>-0.076219</td>\n",
              "      <td>0.170489</td>\n",
              "      <td>-0.832377</td>\n",
              "      <td>0.022601</td>\n",
              "      <td>0.161255</td>\n",
              "      <td>-0.640868</td>\n",
              "      <td>-0.569074</td>\n",
              "      <td>0.040001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.498373</td>\n",
              "      <td>1.282888</td>\n",
              "      <td>-0.188361</td>\n",
              "      <td>-0.947347</td>\n",
              "      <td>0.880581</td>\n",
              "      <td>-0.178855</td>\n",
              "      <td>-0.015432</td>\n",
              "      <td>0.383270</td>\n",
              "      <td>-1.508848</td>\n",
              "      <td>1.753281</td>\n",
              "      <td>-0.754933</td>\n",
              "      <td>0.601241</td>\n",
              "      <td>-0.143784</td>\n",
              "      <td>-0.891944</td>\n",
              "      <td>0.432137</td>\n",
              "      <td>1.346741</td>\n",
              "      <td>-1.485925</td>\n",
              "      <td>1.576216</td>\n",
              "      <td>-0.378781</td>\n",
              "      <td>0.942368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.088144</td>\n",
              "      <td>-0.311402</td>\n",
              "      <td>0.604415</td>\n",
              "      <td>1.713081</td>\n",
              "      <td>1.320312</td>\n",
              "      <td>-3.201303</td>\n",
              "      <td>0.844513</td>\n",
              "      <td>0.962179</td>\n",
              "      <td>-1.535314</td>\n",
              "      <td>2.206953</td>\n",
              "      <td>-0.279025</td>\n",
              "      <td>0.010960</td>\n",
              "      <td>-2.228273</td>\n",
              "      <td>0.204312</td>\n",
              "      <td>-2.175010</td>\n",
              "      <td>1.344161</td>\n",
              "      <td>0.118840</td>\n",
              "      <td>-1.238801</td>\n",
              "      <td>-0.255011</td>\n",
              "      <td>0.695272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.083202</td>\n",
              "      <td>0.694350</td>\n",
              "      <td>-0.293344</td>\n",
              "      <td>0.301429</td>\n",
              "      <td>1.887291</td>\n",
              "      <td>-2.864778</td>\n",
              "      <td>-0.018864</td>\n",
              "      <td>0.176138</td>\n",
              "      <td>-2.388204</td>\n",
              "      <td>1.020881</td>\n",
              "      <td>0.144147</td>\n",
              "      <td>0.802330</td>\n",
              "      <td>-1.326284</td>\n",
              "      <td>-0.055402</td>\n",
              "      <td>-0.268148</td>\n",
              "      <td>1.400147</td>\n",
              "      <td>-1.432996</td>\n",
              "      <td>-1.546905</td>\n",
              "      <td>0.456249</td>\n",
              "      <td>0.117063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.296060</td>\n",
              "      <td>-0.401119</td>\n",
              "      <td>0.260654</td>\n",
              "      <td>-0.133400</td>\n",
              "      <td>0.043096</td>\n",
              "      <td>-0.781329</td>\n",
              "      <td>-0.456910</td>\n",
              "      <td>0.952776</td>\n",
              "      <td>0.359138</td>\n",
              "      <td>0.342683</td>\n",
              "      <td>-1.734295</td>\n",
              "      <td>1.611835</td>\n",
              "      <td>-0.623508</td>\n",
              "      <td>-0.758112</td>\n",
              "      <td>-0.305311</td>\n",
              "      <td>1.009357</td>\n",
              "      <td>-0.759674</td>\n",
              "      <td>-0.749319</td>\n",
              "      <td>-1.216560</td>\n",
              "      <td>0.413135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7608</th>\n",
              "      <td>0.851313</td>\n",
              "      <td>1.155238</td>\n",
              "      <td>-0.563759</td>\n",
              "      <td>0.338048</td>\n",
              "      <td>1.038724</td>\n",
              "      <td>-0.160978</td>\n",
              "      <td>-0.569604</td>\n",
              "      <td>0.691393</td>\n",
              "      <td>-1.027794</td>\n",
              "      <td>-0.184893</td>\n",
              "      <td>-0.310249</td>\n",
              "      <td>1.777828</td>\n",
              "      <td>-1.333608</td>\n",
              "      <td>-1.097076</td>\n",
              "      <td>-0.556300</td>\n",
              "      <td>1.235541</td>\n",
              "      <td>-0.814311</td>\n",
              "      <td>-0.244320</td>\n",
              "      <td>-0.842489</td>\n",
              "      <td>0.383638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7609</th>\n",
              "      <td>0.586044</td>\n",
              "      <td>1.064535</td>\n",
              "      <td>1.108355</td>\n",
              "      <td>-1.080643</td>\n",
              "      <td>0.978821</td>\n",
              "      <td>-1.538974</td>\n",
              "      <td>-0.011408</td>\n",
              "      <td>0.165366</td>\n",
              "      <td>-0.385796</td>\n",
              "      <td>-0.280098</td>\n",
              "      <td>0.166554</td>\n",
              "      <td>-0.024055</td>\n",
              "      <td>-0.658078</td>\n",
              "      <td>-0.365682</td>\n",
              "      <td>-0.477021</td>\n",
              "      <td>1.355311</td>\n",
              "      <td>-0.433643</td>\n",
              "      <td>0.137504</td>\n",
              "      <td>-1.611735</td>\n",
              "      <td>-0.096220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7610</th>\n",
              "      <td>-1.030287</td>\n",
              "      <td>0.200154</td>\n",
              "      <td>-0.691702</td>\n",
              "      <td>-0.506228</td>\n",
              "      <td>0.250602</td>\n",
              "      <td>0.100836</td>\n",
              "      <td>-0.644162</td>\n",
              "      <td>-1.211905</td>\n",
              "      <td>-1.112232</td>\n",
              "      <td>0.593809</td>\n",
              "      <td>-0.752241</td>\n",
              "      <td>0.449338</td>\n",
              "      <td>0.918436</td>\n",
              "      <td>-0.354921</td>\n",
              "      <td>1.325370</td>\n",
              "      <td>-0.197728</td>\n",
              "      <td>-1.613481</td>\n",
              "      <td>0.592320</td>\n",
              "      <td>1.134160</td>\n",
              "      <td>0.184020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7611</th>\n",
              "      <td>0.192334</td>\n",
              "      <td>-0.517235</td>\n",
              "      <td>-0.762114</td>\n",
              "      <td>-0.045759</td>\n",
              "      <td>2.537380</td>\n",
              "      <td>-0.443210</td>\n",
              "      <td>-0.915873</td>\n",
              "      <td>1.407808</td>\n",
              "      <td>0.293244</td>\n",
              "      <td>-0.688244</td>\n",
              "      <td>-2.480736</td>\n",
              "      <td>1.473341</td>\n",
              "      <td>0.463894</td>\n",
              "      <td>-0.913488</td>\n",
              "      <td>-1.088880</td>\n",
              "      <td>2.593801</td>\n",
              "      <td>-0.944662</td>\n",
              "      <td>-0.532709</td>\n",
              "      <td>-1.173615</td>\n",
              "      <td>0.009434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7612</th>\n",
              "      <td>-1.277798</td>\n",
              "      <td>0.167801</td>\n",
              "      <td>0.720873</td>\n",
              "      <td>-0.077118</td>\n",
              "      <td>-0.326406</td>\n",
              "      <td>0.636609</td>\n",
              "      <td>0.309009</td>\n",
              "      <td>-0.878240</td>\n",
              "      <td>-1.077587</td>\n",
              "      <td>1.188922</td>\n",
              "      <td>-0.534988</td>\n",
              "      <td>-1.465944</td>\n",
              "      <td>-0.280353</td>\n",
              "      <td>-0.014573</td>\n",
              "      <td>1.961874</td>\n",
              "      <td>-1.069962</td>\n",
              "      <td>-2.271624</td>\n",
              "      <td>1.095366</td>\n",
              "      <td>0.926221</td>\n",
              "      <td>0.419700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7613 rows × 20 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0         1         2   ...        17        18        19\n",
              "0     0.007239  0.156896  1.295307  ... -0.640868 -0.569074  0.040001\n",
              "1    -0.498373  1.282888 -0.188361  ...  1.576216 -0.378781  0.942368\n",
              "2     0.088144 -0.311402  0.604415  ... -1.238801 -0.255011  0.695272\n",
              "3    -1.083202  0.694350 -0.293344  ... -1.546905  0.456249  0.117063\n",
              "4     0.296060 -0.401119  0.260654  ... -0.749319 -1.216560  0.413135\n",
              "...        ...       ...       ...  ...       ...       ...       ...\n",
              "7608  0.851313  1.155238 -0.563759  ... -0.244320 -0.842489  0.383638\n",
              "7609  0.586044  1.064535  1.108355  ...  0.137504 -1.611735 -0.096220\n",
              "7610 -1.030287  0.200154 -0.691702  ...  0.592320  1.134160  0.184020\n",
              "7611  0.192334 -0.517235 -0.762114  ... -0.532709 -1.173615  0.009434\n",
              "7612 -1.277798  0.167801  0.720873  ...  1.095366  0.926221  0.419700\n",
              "\n",
              "[7613 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTyXZEIOurM-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "a3feeabe-91b5-4f65-fc76-8df45c1f1417"
      },
      "source": [
        "# MANDALE MECHA CON LOS FEATURES MUÑECO\n",
        "train_df = train_df.drop(['id', 'text'],axis = 1)\n",
        "train_df = pd.concat([train_text_embedded_df, train_df], axis=1)\n",
        "\n",
        "train_df['has_mentions'] = train_df['has_mentions'].astype(int)\n",
        "train_df['has_link'] = train_df['has_link'].astype(int)\n",
        "train_df['contains_countries'] = train_df['contains_countries'].astype(int)\n",
        "train_df['contains_cities'] = train_df['contains_cities'].astype(int)\n",
        "\n",
        "train_df"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>character_count</th>\n",
              "      <th>word_count</th>\n",
              "      <th>contains_word_fire</th>\n",
              "      <th>contains_word_storm</th>\n",
              "      <th>contains_word_flood</th>\n",
              "      <th>contains_word_death</th>\n",
              "      <th>contains_word_love</th>\n",
              "      <th>has_mentions</th>\n",
              "      <th>amount_of_exclamation_marks</th>\n",
              "      <th>amount_of_interrogation_marks</th>\n",
              "      <th>has_link</th>\n",
              "      <th>stopwords_count</th>\n",
              "      <th>contains_countries</th>\n",
              "      <th>contains_cities</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.007239</td>\n",
              "      <td>0.156896</td>\n",
              "      <td>1.295307</td>\n",
              "      <td>-0.040780</td>\n",
              "      <td>-0.160369</td>\n",
              "      <td>-1.200443</td>\n",
              "      <td>-0.404513</td>\n",
              "      <td>-0.523973</td>\n",
              "      <td>-0.235587</td>\n",
              "      <td>-0.350222</td>\n",
              "      <td>-0.289882</td>\n",
              "      <td>-0.471979</td>\n",
              "      <td>-0.076219</td>\n",
              "      <td>0.170489</td>\n",
              "      <td>-0.832377</td>\n",
              "      <td>0.022601</td>\n",
              "      <td>0.161255</td>\n",
              "      <td>-0.640868</td>\n",
              "      <td>-0.569074</td>\n",
              "      <td>0.040001</td>\n",
              "      <td>69</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.498373</td>\n",
              "      <td>1.282888</td>\n",
              "      <td>-0.188361</td>\n",
              "      <td>-0.947347</td>\n",
              "      <td>0.880581</td>\n",
              "      <td>-0.178855</td>\n",
              "      <td>-0.015432</td>\n",
              "      <td>0.383270</td>\n",
              "      <td>-1.508848</td>\n",
              "      <td>1.753281</td>\n",
              "      <td>-0.754933</td>\n",
              "      <td>0.601241</td>\n",
              "      <td>-0.143784</td>\n",
              "      <td>-0.891944</td>\n",
              "      <td>0.432137</td>\n",
              "      <td>1.346741</td>\n",
              "      <td>-1.485925</td>\n",
              "      <td>1.576216</td>\n",
              "      <td>-0.378781</td>\n",
              "      <td>0.942368</td>\n",
              "      <td>38</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.088144</td>\n",
              "      <td>-0.311402</td>\n",
              "      <td>0.604415</td>\n",
              "      <td>1.713081</td>\n",
              "      <td>1.320312</td>\n",
              "      <td>-3.201303</td>\n",
              "      <td>0.844513</td>\n",
              "      <td>0.962179</td>\n",
              "      <td>-1.535314</td>\n",
              "      <td>2.206953</td>\n",
              "      <td>-0.279025</td>\n",
              "      <td>0.010960</td>\n",
              "      <td>-2.228273</td>\n",
              "      <td>0.204312</td>\n",
              "      <td>-2.175010</td>\n",
              "      <td>1.344161</td>\n",
              "      <td>0.118840</td>\n",
              "      <td>-1.238801</td>\n",
              "      <td>-0.255011</td>\n",
              "      <td>0.695272</td>\n",
              "      <td>133</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.083202</td>\n",
              "      <td>0.694350</td>\n",
              "      <td>-0.293344</td>\n",
              "      <td>0.301429</td>\n",
              "      <td>1.887291</td>\n",
              "      <td>-2.864778</td>\n",
              "      <td>-0.018864</td>\n",
              "      <td>0.176138</td>\n",
              "      <td>-2.388204</td>\n",
              "      <td>1.020881</td>\n",
              "      <td>0.144147</td>\n",
              "      <td>0.802330</td>\n",
              "      <td>-1.326284</td>\n",
              "      <td>-0.055402</td>\n",
              "      <td>-0.268148</td>\n",
              "      <td>1.400147</td>\n",
              "      <td>-1.432996</td>\n",
              "      <td>-1.546905</td>\n",
              "      <td>0.456249</td>\n",
              "      <td>0.117063</td>\n",
              "      <td>65</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.296060</td>\n",
              "      <td>-0.401119</td>\n",
              "      <td>0.260654</td>\n",
              "      <td>-0.133400</td>\n",
              "      <td>0.043096</td>\n",
              "      <td>-0.781329</td>\n",
              "      <td>-0.456910</td>\n",
              "      <td>0.952776</td>\n",
              "      <td>0.359138</td>\n",
              "      <td>0.342683</td>\n",
              "      <td>-1.734295</td>\n",
              "      <td>1.611835</td>\n",
              "      <td>-0.623508</td>\n",
              "      <td>-0.758112</td>\n",
              "      <td>-0.305311</td>\n",
              "      <td>1.009357</td>\n",
              "      <td>-0.759674</td>\n",
              "      <td>-0.749319</td>\n",
              "      <td>-1.216560</td>\n",
              "      <td>0.413135</td>\n",
              "      <td>88</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7608</th>\n",
              "      <td>0.851313</td>\n",
              "      <td>1.155238</td>\n",
              "      <td>-0.563759</td>\n",
              "      <td>0.338048</td>\n",
              "      <td>1.038724</td>\n",
              "      <td>-0.160978</td>\n",
              "      <td>-0.569604</td>\n",
              "      <td>0.691393</td>\n",
              "      <td>-1.027794</td>\n",
              "      <td>-0.184893</td>\n",
              "      <td>-0.310249</td>\n",
              "      <td>1.777828</td>\n",
              "      <td>-1.333608</td>\n",
              "      <td>-1.097076</td>\n",
              "      <td>-0.556300</td>\n",
              "      <td>1.235541</td>\n",
              "      <td>-0.814311</td>\n",
              "      <td>-0.244320</td>\n",
              "      <td>-0.842489</td>\n",
              "      <td>0.383638</td>\n",
              "      <td>83</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7609</th>\n",
              "      <td>0.586044</td>\n",
              "      <td>1.064535</td>\n",
              "      <td>1.108355</td>\n",
              "      <td>-1.080643</td>\n",
              "      <td>0.978821</td>\n",
              "      <td>-1.538974</td>\n",
              "      <td>-0.011408</td>\n",
              "      <td>0.165366</td>\n",
              "      <td>-0.385796</td>\n",
              "      <td>-0.280098</td>\n",
              "      <td>0.166554</td>\n",
              "      <td>-0.024055</td>\n",
              "      <td>-0.658078</td>\n",
              "      <td>-0.365682</td>\n",
              "      <td>-0.477021</td>\n",
              "      <td>1.355311</td>\n",
              "      <td>-0.433643</td>\n",
              "      <td>0.137504</td>\n",
              "      <td>-1.611735</td>\n",
              "      <td>-0.096220</td>\n",
              "      <td>125</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7610</th>\n",
              "      <td>-1.030287</td>\n",
              "      <td>0.200154</td>\n",
              "      <td>-0.691702</td>\n",
              "      <td>-0.506228</td>\n",
              "      <td>0.250602</td>\n",
              "      <td>0.100836</td>\n",
              "      <td>-0.644162</td>\n",
              "      <td>-1.211905</td>\n",
              "      <td>-1.112232</td>\n",
              "      <td>0.593809</td>\n",
              "      <td>-0.752241</td>\n",
              "      <td>0.449338</td>\n",
              "      <td>0.918436</td>\n",
              "      <td>-0.354921</td>\n",
              "      <td>1.325370</td>\n",
              "      <td>-0.197728</td>\n",
              "      <td>-1.613481</td>\n",
              "      <td>0.592320</td>\n",
              "      <td>1.134160</td>\n",
              "      <td>0.184020</td>\n",
              "      <td>65</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7611</th>\n",
              "      <td>0.192334</td>\n",
              "      <td>-0.517235</td>\n",
              "      <td>-0.762114</td>\n",
              "      <td>-0.045759</td>\n",
              "      <td>2.537380</td>\n",
              "      <td>-0.443210</td>\n",
              "      <td>-0.915873</td>\n",
              "      <td>1.407808</td>\n",
              "      <td>0.293244</td>\n",
              "      <td>-0.688244</td>\n",
              "      <td>-2.480736</td>\n",
              "      <td>1.473341</td>\n",
              "      <td>0.463894</td>\n",
              "      <td>-0.913488</td>\n",
              "      <td>-1.088880</td>\n",
              "      <td>2.593801</td>\n",
              "      <td>-0.944662</td>\n",
              "      <td>-0.532709</td>\n",
              "      <td>-1.173615</td>\n",
              "      <td>0.009434</td>\n",
              "      <td>137</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7612</th>\n",
              "      <td>-1.277798</td>\n",
              "      <td>0.167801</td>\n",
              "      <td>0.720873</td>\n",
              "      <td>-0.077118</td>\n",
              "      <td>-0.326406</td>\n",
              "      <td>0.636609</td>\n",
              "      <td>0.309009</td>\n",
              "      <td>-0.878240</td>\n",
              "      <td>-1.077587</td>\n",
              "      <td>1.188922</td>\n",
              "      <td>-0.534988</td>\n",
              "      <td>-1.465944</td>\n",
              "      <td>-0.280353</td>\n",
              "      <td>-0.014573</td>\n",
              "      <td>1.961874</td>\n",
              "      <td>-1.069962</td>\n",
              "      <td>-2.271624</td>\n",
              "      <td>1.095366</td>\n",
              "      <td>0.926221</td>\n",
              "      <td>0.419700</td>\n",
              "      <td>94</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7613 rows × 34 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             0         1  ...  contains_countries  contains_cities\n",
              "0     0.007239  0.156896  ...                   0                0\n",
              "1    -0.498373  1.282888  ...                   1                0\n",
              "2     0.088144 -0.311402  ...                   0                0\n",
              "3    -1.083202  0.694350  ...                   0                0\n",
              "4     0.296060 -0.401119  ...                   0                0\n",
              "...        ...       ...  ...                 ...              ...\n",
              "7608  0.851313  1.155238  ...                   0                0\n",
              "7609  0.586044  1.064535  ...                   0                0\n",
              "7610 -1.030287  0.200154  ...                   0                0\n",
              "7611  0.192334 -0.517235  ...                   1                1\n",
              "7612 -1.277798  0.167801  ...                   0                0\n",
              "\n",
              "[7613 rows x 34 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddxDogICz-q1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SE DIVIDE UNA PARTE DEL SET PARA PODER EVALUAR LOS RESULTADOS\n",
        "\n",
        "#train_x, validation_x, train_y, validation_y = train_test_split(train_df, target_df, test_size=0.3, random_state=0)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6H0y5CpUmn9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def modelardo(x_train, y_train, x_test, y_test, params):\n",
        "  \n",
        "  input_dim = x_train.shape[1]\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(layers.Dense(params['first neuron units'], \n",
        "                         input_dim = input_dim,\n",
        "                         activation = params['first neuron activation']))\n",
        "  \n",
        "  model.add(layers.Dense(1, \n",
        "                         activation = 'sigmoid'))\n",
        "  \n",
        "  model.compile(loss = 'binary_crossentropy', \n",
        "                optimizer = 'adam', \n",
        "                metrics = ['accuracy'])\n",
        "  \n",
        "  out = model.fit(x_train, \n",
        "                  y_train,\n",
        "                  epochs = params['epochs'],\n",
        "                  verbose = 0, \n",
        "                  validation_data = (x_test, y_test), \n",
        "                  batch_size = params['batch size'])\n",
        "\n",
        "  return out, model\n",
        "\n",
        "\n",
        "p = {\n",
        "    'first neuron units': [1, 2, 20],\n",
        "    'first neuron activation': ['relu', 'elu', 'sigmoid', 'softmax', 'tanh', 'exponential'],\n",
        "    'epochs': [1, 2, 3, 4, 5, 6, 7, 10, 20, 100],\n",
        "    'batch size': [5, 50, 100]\n",
        "}"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyOHfX3z4_C3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "outputId": "91153636-3452-4f63-801b-dd982448a989"
      },
      "source": [
        "# ESTO FALLA\n",
        "t = talos.Scan(train_df.to_numpy(),\n",
        "               target_df.to_numpy(),\n",
        "               params = p,\n",
        "               model = modelardo,\n",
        "               experiment_name = 'diabetes',\n",
        "               time_limit = (dt.datetime.now() + dt.timedelta(minutes = 10)).strftime(\"%Y-%m-%d %H:%M\"),\n",
        "               random_method = 'quantum')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/540 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-914eb2b99d51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                \u001b[0mexperiment_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'diabetes'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                \u001b[0mtime_limit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminutes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y-%m-%d %H:%M\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                random_method = 'quantum')\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/talos/scan/Scan.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, params, model, experiment_name, x_val, y_val, val_split, random_method, seed, performance_target, fraction_limit, round_limit, time_limit, boolean_limit, reduction_method, reduction_interval, reduction_window, reduction_threshold, reduction_metric, minimize_loss, disable_progress_bar, print_params, clear_session, save_weights)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;31m# start runtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mscan_run\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscan_run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mscan_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/talos/scan/scan_run.py\u001b[0m in \u001b[0;36mscan_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# otherwise proceed with next permutation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mscan_round\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscan_round\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscan_round\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/talos/scan/scan_round.py\u001b[0m in \u001b[0;36mscan_round\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mingest_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mingest_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mingest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/talos/model/ingest_model.py\u001b[0m in \u001b[0;36mingest_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      8\u001b[0m                       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                       self.round_params)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-36e2371bb2aa>\u001b[0m in \u001b[0;36mmodelardo\u001b[0;34m(x_train, y_train, x_test, y_test, params)\u001b[0m\n\u001b[1;32m     20\u001b[0m                   \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                   \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                   batch_size = params['batch size'])\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1211\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m             \u001b[0mfit_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m         \u001b[0mfit_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    314\u001b[0m                     training_updates = self.optimizer.get_updates(\n\u001b[1;32m    315\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collected_trainable_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                         loss=self.total_loss)\n\u001b[0m\u001b[1;32m    317\u001b[0m                 \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtraining_updates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mget_updates\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m    502\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_updates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mget_gradients\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             raise ValueError('An operation has `None` for gradient. '\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(loss, variables)\u001b[0m\n\u001b[1;32m   3022\u001b[0m     \"\"\"\n\u001b[1;32m   3023\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_tf_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_ys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mgate_gradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggregation_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         unconnected_gradients)\n\u001b[0m\u001b[1;32m    159\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    556\u001b[0m   \u001b[0;34m\"\"\"Implementation of gradients().\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m     raise RuntimeError(\"tf.gradients is not supported when eager execution \"\n\u001b[0m\u001b[1;32m    559\u001b[0m                        \"is enabled. Use tf.GradientTape instead.\")\n\u001b[1;32m    560\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msrc_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pa9js3I9la4T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# UNA VEZ SOLUCIONADO LO DE ARRIBA, DE ACA PARA ABAJO HAY QUE VER QUE PASA\n",
        "experiment_data = t.data\n",
        "experiment_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t31VOjJynfzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: ACA HAY QUE PONER LOS HIPERPARAMETROS QUE SE ENCONTRARON EN LA BUSQUEDA\n",
        "\n",
        "# Divide el set en train y validation, y entrena con el modelo tomando los hiperparámetros sugeridos\n",
        "\n",
        "x_train, x_validation, y_train, y_validation = train_test_split(data_train,train_df['target'],random_state=7,test_size = 0.20)\n",
        "\n",
        "input_dim = x_train.shape[1]\n",
        "\n",
        "best_model = Sequential()\n",
        "best_model.add(layers.Dense(2,input_dim=input_dim,activation='elu'))\n",
        "best_model.add(layers.Dense(1,activation = 'sigmoid'))\n",
        "best_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "out = best_model.fit(x_train,y_train,epochs = 5,verbose = 0,validation_data = (x_validation,y_validation),batch_size=50)\n",
        "\n",
        "loss, accuracy = best_model.evaluate(x_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "loss, accuracy = best_model.evaluate(x_validation, y_validation, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuY4c8Tdm-7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# EVALUAMOS CON EL SET DE VALIDACION\n",
        "loss, precision = model.evaluate(validation_x, validation_y)\n",
        "print('Precisión: %.2f' % (precision*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCZCJYPK_sLL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: ACA HAY QUE PONER LOS HIPERPARAMETROS QUE SE ENCONTRARON EN LA BUSQUEDA\n",
        "# SE REENTRENA CON EL SET COMPLETO\n",
        "\n",
        "out = best_model.fit(data_train,\n",
        "                     train_df['target'],\n",
        "                     epochs = 5,\n",
        "                     verbose = 1,\n",
        "                     batch_size = 62)\n",
        "data_test = vectorizer.transform(test_df['text']).toarray()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpAEhLQGySbR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ARMAMOS LA PREDICCIÓN\n",
        "prediction = best_model.predict_classes(data_test, batch_size = 512)\n",
        "prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkSvLRovz4i-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DOWNLOAD !\n",
        "test_df['target'] = prediction\n",
        "export = pd.DataFrame()\n",
        "export['id'] = test_df['id']\n",
        "export['target'] = test_df['target']\n",
        "export = export.set_index('id')\n",
        "export.to_csv('submit.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}