{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "Deep Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/francoriboratig/TP2-Datos/blob/master/Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnszrQbpKjPK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "ae366b15-a591-46a9-a7e9-2e79935450b4"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras as krs\n",
        "import tensorflow as tsf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Conv1D,Conv2D,MaxPooling2D\n",
        "from sklearn import model_selection\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import metrics\n",
        "import itertools\n",
        "from google.colab import files\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import csr_matrix, hstack\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "stopwordsList = stopwords.words('english')\n",
        "\n",
        "#url1 = 'https://raw.githubusercontent.com/francoriboratig/TP2-Datos/master/train-bagofwords.csv'\n",
        "#url2 = 'https://raw.githubusercontent.com/francoriboratig/TP2-Datos/master/test-bagofwords.csv'\n",
        "url1 = 'https://raw.githubusercontent.com/JulioCastillo1/TP1-Datos/master/train.csv'\n",
        "url2 = 'https://raw.githubusercontent.com/francoriboratig/TP2-Datos/master/test.csv'\n",
        "\n",
        "train = pd.read_csv(url1)\n",
        "test = pd.read_csv(url2)\n",
        "\n",
        "train.head(5)"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VczEIXh9Fi1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "1aa7c71f-8cba-471c-c260-e8372c1211ad"
      },
      "source": [
        "test.head(5)"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvMPd0mwnFYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Se eliminan stop words\n",
        "\n",
        "ps = PorterStemmer()\n",
        "\n",
        "def dropStopwords(texts):\n",
        "   results=[] \n",
        "   for i in range(0, len(texts)):\n",
        "      text = ' '.join([word for word in texts[i].split() if word not in stopwordsList])\n",
        "      results.append(text)\n",
        "   return results\n",
        "   \n",
        "train['text'] = dropStopwords(train['text'])"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-CePYsZTKQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "classifier=MultinomialNB()\n",
        "TfIdf=TfidfVectorizer()\n"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jN8Hp_ziBxNz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_feature(data, feature):\n",
        "  \n",
        "    return hstack([data, csr_matrix(feature).T], 'csr')\n"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wXneIUQ8-Xe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Se crea el modelo\n",
        "\n",
        "data_target = train[['target']]\n",
        "data_train=train.drop(['id', 'keyword', 'location', 'target'],axis = 1)\n",
        "data_test=test.drop(['keyword', 'location'],axis = 1)\n",
        "\n",
        "#scaler = StandardScaler()\n",
        "#scaler.fit(data_train)\n",
        "\n",
        "#data_train=scaler.transform(data_train)\n",
        "#data_test=scaler.transform(data_test)\n",
        "tokenizer.fit_on_texts(data_train)\n",
        "\n",
        "cv_train = CountVectorizer(analyzer='word',max_features=5660,ngram_range=(1,2),binary=True)\n",
        "\n",
        "data_train_v = cv_train.fit_transform(data_train['text']).toarray()\n",
        "\n",
        "#data_train_v_f = add_feature(data_train_v, data_train['text'].str.len())\n",
        "#data_train_v_f = add_feature(data_train_v_f, data_train['text'].str.replace(r'\\D+', '').str.len())\n",
        "#data_train_v_f = add_feature(data_train_v_f, data_train['text'].str.replace(r'\\w+', '').str.len())\n",
        "#data_train_v_f.shape\n",
        "#data_train_v_f"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY0YTLCkbffD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Se divide el set en train y validation\n",
        "\n",
        "x_train, x_validation, y_train, y_validation = model_selection.train_test_split(data_train_v, data_target, test_size=0.3, random_state=0)\n",
        "\n",
        "cv_train.get_params()\n",
        "cv_train_DF = pd.DataFrame(x_train, columns=cv_train.get_feature_names())\n"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BA149PPzgbBX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#model=krs.Sequential()\n",
        "#model.add(krs.layers.embeddings)\n",
        "#model.add(Conv1D(128, kernel_size=(3),activation='relu'))\n",
        "#model.add(krs.layers.Dense(8, input_dim=2, activation='relu'))\n",
        "#model.add(krs.layers.Dense(8, activation='relu'))\n",
        "#model.add(krs.layers.Dense(2, activation='softmax'))\n",
        "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#model.fit(x_train, y_train, epochs=12, batch_size=128,validation_data=(x_validation,y_validation))"
      ],
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lrdu-r_7o_YJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "7b34151a-7927-4ab2-a35c-a83e6b971cab"
      },
      "source": [
        "# Se entrena y predice\n",
        "#lg=LogisticRegression(C=100).fit(x_train, y_train)\n",
        "#prediction = lg.predict(x_validation)\n",
        "\n",
        "classifier.fit(x_train, y_train)\n",
        "prediction = classifier.predict(x_validation)\n",
        "prediction"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, ..., 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ndU3rz-IaN2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "36368687-aa95-402c-9186-9849ab76d180"
      },
      "source": [
        "# Precisi√≥n (Hasta 3% de diferencia)\n",
        "\n",
        "accuracy=metrics.accuracy_score(y_validation, prediction)\n",
        "accuracy"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8117338003502627"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiSDWXjW-UHk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9af2d3aa-e436-423d-f36f-b5a3e0447134"
      },
      "source": [
        "score = roc_auc_score(y_validation, prediction)\n",
        "score"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7934770586246235"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKG4R3vEQo4F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "fc634605-6a83-4382-d606-26d14d46edf9"
      },
      "source": [
        "#data_target = countV.fit_transform(data_target['target']).toarray()\n",
        "#data_target.shape\n",
        "#cv_train2 = CountVectorizer(max_features=5000,ngram_range=(1,2))\n",
        "#cv_train.get_params()\n",
        "#cv_train2_DF = pd.DataFrame(data_train, columns=cv_train.get_feature_names())\n",
        "\n",
        "classifier.fit(data_train_v, data_target)\n",
        "\n",
        "#lg=LogisticRegression(C=100).fit(data_train_v, data_target)\n",
        "\n"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAul0x2JvNXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Se predice con test luego de reentrenar con el set completo\n",
        "\n",
        "cv_test = CountVectorizer(vocabulary=cv_train.get_feature_names(),analyzer='word',max_features=5660,ngram_range=(1,2),binary=True)\n",
        "\n",
        "x_test = cv_test.transform(data_test['text']).toarray()\n",
        "x_test.shape\n",
        "\n",
        "cv_test.get_params()\n",
        "cv_test_DF = pd.DataFrame(x_test, columns=cv_test.get_feature_names())\n",
        "\n",
        "prediction2 = classifier.predict(x_test)\n",
        "\n",
        "#predictions = lg.predict(x_test)\n"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4jIFTzIhEqp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "f77763ea-92ef-4b6e-ecfa-f6176b013459"
      },
      "source": [
        "x_test"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWM9-JZ1gAP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Se genera submit\n",
        "\n",
        "data_test['target'] = prediction2\n",
        "export = pd.DataFrame()\n",
        "export['id'] = data_test['id']\n",
        "export['target'] = data_test['target']\n",
        "export = export.set_index('id')\n",
        "export.to_csv('submit.csv')\n",
        "#files.download('submit.csv')"
      ],
      "execution_count": 189,
      "outputs": []
    }
  ]
}